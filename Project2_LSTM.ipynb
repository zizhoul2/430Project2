{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a516143-534d-4ca8-8d6c-1a2859fe870c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d920d6f0-5b0c-479c-932f-4271d3cd8e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('weather_data_09_to_16.csv')\n",
    "\n",
    "# Drop rows with missing target\n",
    "df = df.dropna(subset=['RainTomorrow'])\n",
    "\n",
    "# Binary encode target: Yes -> 1, No -> 0\n",
    "df['RainTomorrow'] = df['RainTomorrow'].map({'No': 0, 'Yes': 1})\n",
    "\n",
    "# Select numeric + useful features\n",
    "features = ['MinTemp', 'MaxTemp', 'Rainfall', 'Humidity9am', 'Humidity3pm', 'Pressure9am', 'Pressure3pm', 'Temp9am', 'Temp3pm']\n",
    "df = df.dropna(subset=features)\n",
    "\n",
    "X = df[features]\n",
    "y = df['RainTomorrow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9142d3e-d375-4a36-a74e-919afe8e2600",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Reshape to [samples, time steps, features]; here using 1 timestep\n",
    "X_reshaped = X_scaled.reshape((X_scaled.shape[0], 1, X_scaled.shape[1]))\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5028535b-6645-4942-86bf-4301431552e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">70,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │        \u001b[38;5;34m70,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m49,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">122,177</span> (477.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m122,177\u001b[0m (477.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">122,177</span> (477.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m122,177\u001b[0m (477.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# First LSTM layer: use more units and return full sequence\n",
    "model.add(LSTM(128, input_shape=(1, 9), return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Second LSTM layer: compress sequence to single vector\n",
    "model.add(LSTM(64, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Dense layer before output\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e62b316-3bde-40f9-8816-a11329baf57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8012 - loss: 0.4758 - val_accuracy: 0.8398 - val_loss: 0.3826\n",
      "Epoch 2/30\n",
      "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8406 - loss: 0.3799 - val_accuracy: 0.8403 - val_loss: 0.3772\n",
      "Epoch 3/30\n",
      "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8382 - loss: 0.3843 - val_accuracy: 0.8395 - val_loss: 0.3743\n",
      "Epoch 4/30\n",
      "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8406 - loss: 0.3763 - val_accuracy: 0.8410 - val_loss: 0.3738\n",
      "Epoch 5/30\n",
      "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8430 - loss: 0.3807 - val_accuracy: 0.8392 - val_loss: 0.3746\n",
      "Epoch 6/30\n",
      "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8427 - loss: 0.3769 - val_accuracy: 0.8412 - val_loss: 0.3728\n",
      "Epoch 7/30\n",
      "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3713 - val_accuracy: 0.8402 - val_loss: 0.3721\n",
      "Epoch 8/30\n",
      "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8395 - loss: 0.3808 - val_accuracy: 0.8424 - val_loss: 0.3724\n",
      "Epoch 9/30\n",
      "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8392 - loss: 0.3807 - val_accuracy: 0.8362 - val_loss: 0.3812\n",
      "Epoch 10/30\n",
      "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8380 - loss: 0.3825 - val_accuracy: 0.8381 - val_loss: 0.3861\n",
      "Epoch 11/30\n",
      "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8465 - loss: 0.3742 - val_accuracy: 0.8395 - val_loss: 0.3775\n",
      "Epoch 12/30\n",
      "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8441 - loss: 0.3734 - val_accuracy: 0.8398 - val_loss: 0.3701\n",
      "Epoch 13/30\n",
      "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8441 - loss: 0.3712 - val_accuracy: 0.8414 - val_loss: 0.3683\n",
      "Epoch 14/30\n",
      "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8439 - loss: 0.3735 - val_accuracy: 0.8393 - val_loss: 0.3772\n",
      "Epoch 15/30\n",
      "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8428 - loss: 0.3748 - val_accuracy: 0.8409 - val_loss: 0.3674\n",
      "Epoch 16/30\n",
      "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8408 - loss: 0.3782 - val_accuracy: 0.8400 - val_loss: 0.3681\n",
      "Epoch 17/30\n",
      "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8420 - loss: 0.3747 - val_accuracy: 0.8402 - val_loss: 0.3721\n",
      "Epoch 18/30\n",
      "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8419 - loss: 0.3751 - val_accuracy: 0.8350 - val_loss: 0.3852\n",
      "Epoch 19/30\n",
      "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8447 - loss: 0.3700 - val_accuracy: 0.8400 - val_loss: 0.3668\n",
      "Epoch 20/30\n",
      "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8468 - loss: 0.3669 - val_accuracy: 0.8386 - val_loss: 0.3789\n",
      "Epoch 21/30\n",
      "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8406 - loss: 0.3788 - val_accuracy: 0.8407 - val_loss: 0.3669\n",
      "Epoch 22/30\n",
      "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8408 - loss: 0.3755 - val_accuracy: 0.8403 - val_loss: 0.3733\n",
      "Epoch 23/30\n",
      "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8430 - loss: 0.3727 - val_accuracy: 0.8400 - val_loss: 0.3684\n",
      "Epoch 24/30\n",
      "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8384 - loss: 0.3816 - val_accuracy: 0.8405 - val_loss: 0.3631\n",
      "Epoch 25/30\n",
      "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8409 - loss: 0.3765 - val_accuracy: 0.8407 - val_loss: 0.3663\n",
      "Epoch 26/30\n",
      "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8428 - loss: 0.3706 - val_accuracy: 0.8414 - val_loss: 0.3680\n",
      "Epoch 27/30\n",
      "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8429 - loss: 0.3699 - val_accuracy: 0.8409 - val_loss: 0.3643\n",
      "Epoch 28/30\n",
      "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8442 - loss: 0.3743 - val_accuracy: 0.8414 - val_loss: 0.3647\n",
      "Epoch 29/30\n",
      "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8451 - loss: 0.3703 - val_accuracy: 0.8410 - val_loss: 0.3622\n",
      "Epoch 30/30\n",
      "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8478 - loss: 0.3700 - val_accuracy: 0.8424 - val_loss: 0.3620\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d22edd97-f021-4ecf-88f4-72c88a3cd422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - accuracy: 0.8372 - loss: 0.3759\n",
      "Test Accuracy: 0.8424\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39afbd90-57f9-4b78-a262-79c53aa8609f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "[[4365  211]\n",
      " [ 710  558]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90      4576\n",
      "           1       0.73      0.44      0.55      1268\n",
      "\n",
      "    accuracy                           0.84      5844\n",
      "   macro avg       0.79      0.70      0.73      5844\n",
      "weighted avg       0.83      0.84      0.83      5844\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b4358cb-2c3f-40a4-86e7-e98fb893be5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step\n",
      "AUC: 0.8557\n"
     ]
    }
   ],
   "source": [
    "y_probs = model.predict(X_test).flatten()  # Predict probabilities for test set\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# y_probs = model.predict(X_test).flatten()  # Already predicted probabilities\n",
    "auc_score = roc_auc_score(y_test, y_probs)\n",
    "print(f\"AUC: {auc_score:.4f}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bb3d8655-81ea-4c12-8e71-ee52d3a3cd7c",
   "metadata": {},
   "source": [
    "_____________________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9347b529-d0f4-4ac8-bd76-eaee2d940a1f",
   "metadata": {},
   "source": [
    "_____________________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504ecba0-15e0-49c9-b3da-20716a2a288b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 days timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c07100d-53c3-4da3-8b18-063344d598af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('weather_data_09_to_16.csv')\n",
    "\n",
    "# Target column\n",
    "df = df.dropna(subset=['RainTomorrow'])\n",
    "df['RainTomorrow'] = df['RainTomorrow'].map({'No': 0, 'Yes': 1})\n",
    "\n",
    "# Feature columns\n",
    "features = ['MinTemp', 'MaxTemp', 'Rainfall', 'Humidity9am', 'Humidity3pm',\n",
    "            'Pressure9am', 'Pressure3pm', 'Temp9am', 'Temp3pm']\n",
    "df = df.dropna(subset=features)\n",
    "df = df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a2010b-60cc-4c1c-9127-2cb3124785ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(df[features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2933fbb-d814-48f8-958d-beac3098ad75",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_seq = []\n",
    "y_seq = []\n",
    "\n",
    "sequence_length = 7  # 7 days input\n",
    "\n",
    "for i in range(len(X_scaled) - sequence_length):\n",
    "    X_seq.append(X_scaled[i:i+sequence_length])  # shape (7, 9)\n",
    "    y_seq.append(df['RainTomorrow'].iloc[i + sequence_length])  # 8th day target\n",
    "\n",
    "X_seq = np.array(X_seq)  # shape: (samples, 7, 9)\n",
    "y_seq = np.array(y_seq)  # shape: (samples,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0ff1f9-5100-43fc-953a-032e6c32e02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af11529-eda3-412a-a584-d89503d8431c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# First LSTM layer: returns full sequence to stack\n",
    "model.add(LSTM(128, input_shape=(7, 9), return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Second LSTM layer: compresses sequence to 64-dim vector\n",
    "model.add(LSTM(64, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Dense hidden layer before output\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "# Final output layer for binary classification\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892e964b-b9c0-4766-bac5-4f5fa2aeba72",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513b53be-05e6-44c5-a1e4-61c04ad03152",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e5d344-c649-45b4-bca6-01fadb079e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Predict probabilities\n",
    "y_pred_prob = model.predict(X_test)\n",
    "\n",
    "# Convert probabilities to class labels\n",
    "y_pred = (y_pred_prob > 0.5).astype(\"int32\").flatten()\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['No Rain', 'Rain']))\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "22128649-0aca-4a74-9a36-ae38b07ad3c8",
   "metadata": {},
   "source": [
    "_____________________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a0b79832-ef05-4d1f-bd7e-a31e9aa5096d",
   "metadata": {},
   "source": [
    "_____________________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3f8903-73c9-45a8-9783-139f8650f1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 1. Import Libraries =====\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe413a6-4b7c-4cfe-a492-da1da8ad7067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 2. Load and Preprocess Data =====\n",
    "df = pd.read_csv('weather_data_09_to_16.csv')\n",
    "\n",
    "# Drop rows where target is missing\n",
    "df = df.dropna(subset=['RainTomorrow'])\n",
    "\n",
    "# Convert target to binary: Yes -> 1, No -> 0\n",
    "df['RainTomorrow'] = df['RainTomorrow'].map({'No': 0, 'Yes': 1})\n",
    "\n",
    "# Select numeric input features\n",
    "features = ['MinTemp', 'MaxTemp', 'Rainfall', 'Humidity9am', 'Humidity3pm',\n",
    "            'Pressure9am', 'Pressure3pm', 'Temp9am', 'Temp3pm']\n",
    "\n",
    "# Drop rows with missing features\n",
    "df = df.dropna(subset=features)\n",
    "df = df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8ea923-2d6c-4180-842f-6eb91e87b52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 3. Normalize Features =====\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(df[features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3bb1b1-b9b8-4a60-a3da-d9a2bb583ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 4. Create 14-Day Rolling Sequences =====\n",
    "X_seq = []\n",
    "y_seq = []\n",
    "\n",
    "sequence_length = 14  # 14 timesteps (days)\n",
    "\n",
    "for i in range(len(X_scaled) - sequence_length):\n",
    "    X_seq.append(X_scaled[i:i+sequence_length])  # shape: (14, 9)\n",
    "    y_seq.append(df['RainTomorrow'].iloc[i + sequence_length])  # label: day 15\n",
    "\n",
    "X_seq = np.array(X_seq)  # shape: (samples, 14, 9)\n",
    "y_seq = np.array(y_seq)  # shape: (samples,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45291d22-c999-4bac-9696-0f7a92561396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 5. Train/Test Split =====\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b73500-a1e6-4d81-bc04-fd632dc3555a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 6. Build LSTM Model =====\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(14, 9), return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(64, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bceeeb10-ae82-4b60-9e64-bc2e41d5616e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 7. Train the Model =====\n",
    "history = model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b6505c-c797-4510-9191-b9240e71c64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 8. Evaluate & Report =====\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Predictions\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(\"int32\").flatten()\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['No Rain', 'Rain']))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
